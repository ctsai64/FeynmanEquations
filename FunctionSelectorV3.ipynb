{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.optim.lr_scheduler import StepLR, LambdaLR\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Func(nn.Module):\n",
    "    def __init__(self, functions, num_params, symbols, x_data, input_channels, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.functions = functions\n",
    "        self.x_data = x_data.to(self.device)\n",
    "        self.input_channels = input_channels\n",
    "        self.num_params = num_params\n",
    "        self.max_params = max(num_params)\n",
    "        self.total_params = sum(self.num_params)\n",
    "        self.symbols = symbols\n",
    "\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.input_channels, out_channels=8, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(64)\n",
    "        )\n",
    "\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(32, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(16),\n",
    "            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(8),\n",
    "            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(4),\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(28, 128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, self.total_params),\n",
    "        )\n",
    "\n",
    "    def evaluate(self, params, index):\n",
    "        symbols = self.symbols[index]\n",
    "        formula = self.functions[index]\n",
    "        x = self.x_data\n",
    "        var_values = {str(symbols[j]): params[:, j] for j in range(len(symbols)-1)}\n",
    "        eval_func = sp.lambdify(symbols, formula, modules=\"numpy\")\n",
    "        var_values[str(symbols[-1])] = x.unsqueeze(1)\n",
    "        results = eval_func(**var_values)\n",
    "        results = torch.nan_to_num(results, 0)\n",
    "        return results.swapaxes(0,1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        target = inputs.squeeze(dim=2)\n",
    "        outs = torch.swapaxes(inputs, 1, 2).to(self.device)\n",
    "        outs = self.hidden_x1(outs)\n",
    "        xfc = torch.reshape(outs, (-1, 256))\n",
    "        xfc = self.hidden_xfc(xfc)\n",
    "\n",
    "        outs = torch.reshape(outs, (-1, 2, 128))\n",
    "        outs = self.hidden_x2(outs)\n",
    "        cnn_flat = self.flatten_layer(outs)\n",
    "        encoded = torch.cat((cnn_flat, xfc), 1)\n",
    "        embedding = self.hidden_embedding(encoded)\n",
    "\n",
    "        loss_func = nn.MSELoss()\n",
    "        start_index = 0\n",
    "        losses = []\n",
    "        outputs = []\n",
    "        all_params = []\n",
    "        \n",
    "        for f in range(len(self.functions)):\n",
    "            params = embedding[:, start_index:start_index+self.num_params[f]]\n",
    "            all_params.append(params)\n",
    "            output = self.evaluate(params, f).to(self.device)\n",
    "            outputs.append(output)\n",
    "            loss = loss_func(output, target)\n",
    "            losses.append(loss)\n",
    "            start_index += self.num_params[f]        \n",
    "        best_index = torch.argmin(torch.tensor(losses))\n",
    "        best_func = self.functions[best_index]\n",
    "        best_loss, best_out = losses[best_index], outputs[best_index]\n",
    "\n",
    "        return best_out, best_loss, best_func, outputs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1052847/3483314352.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load('hold_data.pth')\n"
     ]
    }
   ],
   "source": [
    "loaded_data = torch.load('hold_data.pth')\n",
    "\n",
    "x_values = loaded_data['x_values'].to(device)\n",
    "y_values = loaded_data['y_values'].to(device)\n",
    "derivatives = loaded_data['derivatives'].to(device)\n",
    "params = loaded_data['param_values'].to(device)\n",
    "functions = loaded_data['formulas']\n",
    "symbols = loaded_data['symbols']\n",
    "num_params = loaded_data['num_params'].to(device)\n",
    "function_labels = loaded_data['function_labels'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_values: torch.Size([100])\n",
      "y_values: torch.Size([10000, 100])\n",
      "derivatives: torch.Size([10000, 100, 5])\n",
      "param_values: torch.Size([10000, 5])\n",
      "formulas: 10\n",
      "symbols: 10\n",
      "num_params: torch.Size([10])\n",
      "function_labels: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_values: {x_values.shape}\")\n",
    "print(f\"y_values: {y_values.shape}\")\n",
    "print(f\"derivatives: {derivatives.shape}\")\n",
    "#print(f\"hessians: {hessians.shape}\")\n",
    "print(f\"param_values: {params.shape}\")\n",
    "print(f\"formulas: {len(functions)}\")\n",
    "print(f\"symbols: {len(symbols)}\")\n",
    "print(f\"num_params: {num_params.shape}\")\n",
    "print(f\"function_labels: {function_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(y_values, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cymberly/FeynmanEquations/.conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([100, 100, 1])) that is different to the input size (torch.Size([100, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0/50, loss = 10581.30279907\n",
      "--- 1.5102672576904297 seconds ---\n",
      "epoch : 1/50, loss = 10574.69818176\n",
      "--- 1.3758680820465088 seconds ---\n",
      "epoch : 2/50, loss = 10573.87543823\n",
      "--- 1.3611598014831543 seconds ---\n",
      "epoch : 3/50, loss = 10573.77061707\n",
      "--- 1.3608167171478271 seconds ---\n",
      "epoch : 4/50, loss = 10574.72953003\n",
      "--- 1.3623239994049072 seconds ---\n",
      "epoch : 5/50, loss = 10810.06403748\n",
      "--- 1.3638112545013428 seconds ---\n",
      "epoch : 6/50, loss = 10574.95321777\n",
      "--- 1.3669536113739014 seconds ---\n",
      "epoch : 7/50, loss = 10573.61445877\n",
      "--- 1.3547513484954834 seconds ---\n",
      "epoch : 8/50, loss = 10574.52816650\n",
      "--- 1.365250825881958 seconds ---\n",
      "epoch : 9/50, loss = 10574.22498169\n",
      "--- 1.3508191108703613 seconds ---\n",
      "epoch : 10/50, loss = 10574.13523438\n",
      "--- 1.3562588691711426 seconds ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m best_out,_,_,_,_ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(best_out,train_batch)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 100\u001b[0m, in \u001b[0;36mMulti_Func.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     98\u001b[0m params \u001b[38;5;241m=\u001b[39m embedding[:, start_index:start_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_params[f]]\n\u001b[1;32m     99\u001b[0m all_params\u001b[38;5;241m.\u001b[39mappend(params)\n\u001b[0;32m--> 100\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    101\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    102\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, target)\n",
      "Cell \u001b[0;32mIn[19], line 72\u001b[0m, in \u001b[0;36mMulti_Func.evaluate\u001b[0;34m(self, params, index)\u001b[0m\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_data\n\u001b[1;32m     71\u001b[0m var_values \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mstr\u001b[39m(symbols[j]): params[:, j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(symbols)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)}\n\u001b[0;32m---> 72\u001b[0m eval_func \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambdify\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumpy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m var_values[\u001b[38;5;28mstr\u001b[39m(symbols[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])] \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m results \u001b[38;5;241m=\u001b[39m eval_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvar_values)\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/utilities/lambdify.py:919\u001b[0m, in \u001b[0;36mlambdify\u001b[0;34m(args, expr, modules, printer, use_imps, dummify, cse, docstring_limit)\u001b[0m\n\u001b[1;32m    917\u001b[0m     src_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSOURCE CODE REDACTED DUE TO LENGTH, (see lambdify\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `docstring_limit`)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 919\u001b[0m     expr_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(expr)\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expr_str) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m78\u001b[39m:\n\u001b[1;32m    921\u001b[0m         expr_str \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mwrap(expr_str, \u001b[38;5;241m75\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/core/_print_helpers.py:29\u001b[0m, in \u001b[0;36mPrintable.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprinting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sstr\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msstr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/printing/printer.py:372\u001b[0m, in \u001b[0;36m_PrintFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/printing/str.py:995\u001b[0m, in \u001b[0;36msstr\u001b[0;34m(expr, **settings)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the expression as a string.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \n\u001b[1;32m    981\u001b[0m \u001b[38;5;124;03mFor large expressions where speed is a concern, use the setting\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m'Eq(a + b, 0)'\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    994\u001b[0m p \u001b[38;5;241m=\u001b[39m StrPrinter(settings)\n\u001b[0;32m--> 995\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/printing/printer.py:292\u001b[0m, in \u001b[0;36mPrinter.doprint\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdoprint\u001b[39m(\u001b[38;5;28mself\u001b[39m, expr):\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns printer's representation for expr (as a string)\"\"\"\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/printing/printer.py:331\u001b[0m, in \u001b[0;36mPrinter._print\u001b[0;34m(self, expr, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m     printmethod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, printmethodname, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m printmethod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprintmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# Unknown object, fall back to the emptyPrinter.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memptyPrinter(expr)\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/printing/str.py:325\u001b[0m, in \u001b[0;36mStrPrinter._print_Mul\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m    322\u001b[0m pow_paren \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Will collect all pow with more than one base element and exp = -1\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mold\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 325\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_ordered_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# use make_args in case expr was something like -x -> x\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     args \u001b[38;5;241m=\u001b[39m Mul\u001b[38;5;241m.\u001b[39mmake_args(expr)\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/core/mul.py:2087\u001b[0m, in \u001b[0;36mMul.as_ordered_factors\u001b[0;34m(self, order)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform an expression into an ordered list of factors.\u001b[39;00m\n\u001b[1;32m   2075\u001b[0m \n\u001b[1;32m   2076\u001b[0m \u001b[38;5;124;03mExamples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \n\u001b[1;32m   2085\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2086\u001b[0m cpart, ncpart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs_cnc()\n\u001b[0;32m-> 2087\u001b[0m \u001b[43mcpart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cpart \u001b[38;5;241m+\u001b[39m ncpart\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/core/mul.py:2087\u001b[0m, in \u001b[0;36mMul.as_ordered_factors.<locals>.<lambda>\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform an expression into an ordered list of factors.\u001b[39;00m\n\u001b[1;32m   2075\u001b[0m \n\u001b[1;32m   2076\u001b[0m \u001b[38;5;124;03mExamples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \n\u001b[1;32m   2085\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2086\u001b[0m cpart, ncpart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs_cnc()\n\u001b[0;32m-> 2087\u001b[0m cpart\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m expr: \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cpart \u001b[38;5;241m+\u001b[39m ncpart\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/core/cache.py:72\u001b[0m, in \u001b[0;36m__cacheit.<locals>.func_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m         retval \u001b[38;5;241m=\u001b[39m \u001b[43mcfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munhashable type:\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/sympy/core/basic.py:256\u001b[0m, in \u001b[0;36mBasic.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__reduce_ex__(protocol)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# hash cannot be cached using cache_it because infinite recurrence\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# occurs as hash is needed for setting cache dictionary keys\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mhash\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Multi_Func(functions, num_params, symbols, x_values, 1, device).to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    total_num = 0\n",
    "    model.train()\n",
    "    \n",
    "    for train_batch in dataloader:\n",
    "        train_batch = train_batch.unsqueeze(2).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        best_out,_,_,_,_ = model(train_batch)\n",
    "        loss = loss_func(best_out,train_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * best_out.shape[0]\n",
    "        total_num += best_out.shape[0]\n",
    "    scheduler.step()\n",
    "    train_loss /= total_num\n",
    "    print(f\"epoch : {epoch}/{epochs}, loss = {train_loss:.8f}\")\n",
    "    print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
