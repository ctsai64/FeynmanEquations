{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numdifftools as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, func in enumerate(functions):\\n    print(f\"Function {i+1}:\")\\n    print(f\"  Formula: {func[\\'formula\\']}\")\\n    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\\n    print(\"  Variables:\")\\n    for var in func[\\'variables\\']:\\n        print(f\"    - Name: {var[\\'name\\']}, Range: ({var[\\'low\\']}, {var[\\'high\\']})\")\\n    print()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('physics_equations.csv')\n",
    "\n",
    "functions = []\n",
    "num_vars_per_func = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    formula = row['Formula']\n",
    "    num_vars = row['# variables']\n",
    "    function_details = {\n",
    "        'formula': formula,\n",
    "        'variables': []\n",
    "    }\n",
    "    \n",
    "    for i in range(1, 11):  \n",
    "        v_name = row.get(f'v{i}_name', None)\n",
    "        v_low = row.get(f'v{i}_low', None)\n",
    "        v_high = row.get(f'v{i}_high', None)\n",
    "        \n",
    "        if pd.notna(v_name):\n",
    "            function_details['variables'].append({\n",
    "                'name': v_name,\n",
    "                'low': v_low,\n",
    "                'high': v_high\n",
    "            })\n",
    "    \n",
    "    functions.append(function_details)\n",
    "    num_vars_per_func.append(num_vars)\n",
    "\n",
    "'''for i, func in enumerate(functions):\n",
    "    print(f\"Function {i+1}:\")\n",
    "    print(f\"  Formula: {func['formula']}\")\n",
    "    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\n",
    "    print(\"  Variables:\")\n",
    "    for var in func['variables']:\n",
    "        print(f\"    - Name: {var['name']}, Range: ({var['low']}, {var['high']})\")\n",
    "    print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function(function, sample_size, x, max_vars, device):\n",
    "    sympy_symbols = []\n",
    "    param_tensors = []\n",
    "    \n",
    "    for var in function[\"variables\"]:\n",
    "        sym = sp.symbols(var[\"name\"])\n",
    "        sympy_symbols.append(sym)\n",
    "        min_val, max_val = var[\"low\"], var[\"high\"]\n",
    "        param = (max_val - min_val) * torch.rand(sample_size, 1, device=device) + min_val\n",
    "        param_tensors.append(param)\n",
    "\n",
    "    sympy_symbols.append(sp.symbols('x'))\n",
    "    params = torch.cat(param_tensors, dim=1)\n",
    "    padded_params = F.pad(params, pad=(0, max_vars - params.size(1)))\n",
    "    padded_params = padded_params.expand(sample_size, max_vars)\n",
    "    formula = sp.sympify(function[\"formula\"])\n",
    "    eval_func = sp.lambdify(sympy_symbols, formula, modules=\"numpy\")\n",
    "        \n",
    "    results = []\n",
    "    for xi in x:\n",
    "        input_values = torch.cat([params, xi.expand(sample_size, 1)], dim=1)\n",
    "        results.append(eval_func(*input_values.T))\n",
    "    results = torch.stack(results, dim=1)\n",
    "    \n",
    "    return results, formula, sympy_symbols, padded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "sequence_length = 100\n",
    "num_funcs = 10\n",
    "max_vars = 5\n",
    "\n",
    "x_values = torch.linspace(-1, 1, sequence_length).to(device)\n",
    "hold = []\n",
    "for f in functions[0:10]:\n",
    "    try:\n",
    "        results = generate_function(f, sample_size, x_values, max_vars, device)\n",
    "        hold.append(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing function {f}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = torch.stack([l[0] for l in hold])\n",
    "formulas = [l[1] for l in hold]\n",
    "symbols = [l[2] for l in hold]\n",
    "param_values = torch.stack([l[3] for l in hold])\n",
    "num_params = torch.tensor([len(l[2]) for l in hold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_function(params, symbols, formula, x):\n",
    "    var_values = {symbols[j]: params[:, j] for j in range(len(symbols)-1)}\n",
    "    eval_func = sp.lambdify(symbols, formula, modules=\"numpy\")\n",
    "    results = []\n",
    "    for xi in x:\n",
    "        var_values[symbols[-1]] = xi\n",
    "        np_values = {str(sym): var_values[sym].detach().cpu().numpy() for sym in symbols}\n",
    "        results.append(eval_func(**np_values))\n",
    "    tensor_results = [torch.tensor(r, device=device) for r in results]\n",
    "    return torch.stack(tensor_results, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000, 100, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1e-4\n",
    "derivatives = torch.zeros(num_funcs, sample_size, sequence_length, max_vars)\n",
    "for f in range(num_funcs):\n",
    "    params_n = param_values[f].clone().detach().requires_grad_(True)\n",
    "    for p in range(len(symbols[f])):\n",
    "        plus = params_n.clone()\n",
    "        minus = params_n.clone()\n",
    "        plus[:,p] += epsilon\n",
    "        forward_values = evaluate_function(plus, symbols[f], formulas[f], x_values)\n",
    "        minus[:, p] -= epsilon\n",
    "        backward_values = evaluate_function(minus, symbols[f], formulas[f], x_values)\n",
    "        derivatives[f, :, :, p] = (forward_values - backward_values) / (2 * epsilon)\n",
    "derivatives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000, 100, 5, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians = torch.zeros(num_funcs, sample_size, sequence_length, max_vars, max_vars)\n",
    "for f in range(num_funcs):\n",
    "    params_f = param_values[f].clone().detach().requires_grad_(True)\n",
    "    for j in range(len(symbols[f])):\n",
    "        for k in range(len(symbols[f])):\n",
    "            plus_plus = params_f.clone()\n",
    "            plus_minus = params_f.clone()\n",
    "            minus_plus = params_f.clone()\n",
    "            minus_minus = params_f.clone()\n",
    "\n",
    "            plus_plus[:, j] += epsilon\n",
    "            plus_plus[:, k] += epsilon\n",
    "\n",
    "            plus_minus[:, j] += epsilon\n",
    "            plus_minus[:, k] -= epsilon\n",
    "\n",
    "            minus_plus[:, j] -= epsilon\n",
    "            minus_plus[:, k] += epsilon\n",
    "\n",
    "            minus_minus[:, j] -= epsilon\n",
    "            minus_minus[:, k] -= epsilon\n",
    "\n",
    "            forward_forward = evaluate_function(plus_plus, symbols[f], formulas[f], x_values)\n",
    "            forward_backward = evaluate_function(plus_minus, symbols[f], formulas[f], x_values)\n",
    "            backward_forward = evaluate_function(minus_plus, symbols[f], formulas[f], x_values)\n",
    "            backward_backward = evaluate_function(minus_minus, symbols[f], formulas[f], x_values)\n",
    "            hessians[f, :, :, j, k] = (forward_forward - forward_backward - backward_forward + backward_backward) / (4 * epsilon **2)\n",
    "hessians.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]),\n",
       " tensor(-1., device='cuda:4'),\n",
       " t/x,\n",
       " tensor([0.1069, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:4'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 81]), torch.Size([10000, 81]), torch.Size([10000, 81]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_result = torch.flatten(torch.stack(y_values).unsqueeze(2), start_dim=0, end_dim=1)\n",
    "\n",
    "max_der = max(d.size(1) for d in derivatives)\n",
    "padded_ders = []\n",
    "for d in derivatives:\n",
    "    padded_tensor = F.pad(d, pad=(0, max_der - d.size(1)))\n",
    "    padded_ders.append(padded_tensor)\n",
    "flat_der = torch.flatten(torch.stack(padded_ders), start_dim=0, end_dim=1)\n",
    "\n",
    "max_hess = max_der**2\n",
    "padded_hess = []\n",
    "for h in hessians:\n",
    "    h = torch.flatten(h, start_dim=1)\n",
    "    padded_tensor = F.pad(h, pad=(0, max_hess - h.size(1)))\n",
    "    padded_hess.append(padded_tensor)\n",
    "flat_hess = torch.flatten(torch.stack(padded_hess), start_dim=0, end_dim=1)\n",
    "\n",
    "flat_der = F.pad(flat_der, (0, flat_hess.size(-1) - flat_der.size(-1)))\n",
    "flat_result = F.pad(flat_result, (0, flat_hess.size(-1) - flat_result.size(-1)))\n",
    "\n",
    "flat_result.shape, flat_der.shape, flat_hess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_params = torch.repeat_interleave(num_params, repeats=sample_size)\n",
    "y_values = torch.flatten(y_values, end_dim=1)\n",
    "param_values = torch.flatten(param_values, end_dim=1)\n",
    "formulas = np.array([[formula for _ in range(1000)] for formula in formulas]).flatten()\n",
    "symbols = []\n",
    "for s in symbols_hold:\n",
    "    for _ in range(sample_size):\n",
    "        symbols.append(s)\n",
    "\n",
    "y_values.shape, param_values.shape, num_params.shape, formulas.shape, len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'flattened_data': torch.stack([flat_result, flat_der, flat_hess], dim=2),\n",
    "    'results': y_values,\n",
    "    'formulas': hold_formulas,\n",
    "    'symbols': hold_symbols,\n",
    "    'params': param_values,\n",
    "    'num_params': num_params,\n",
    "}, 'hold_data.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
