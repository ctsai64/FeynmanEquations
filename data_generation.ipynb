{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, func in enumerate(functions):\\n    print(f\"Function {i+1}:\")\\n    print(f\"  Formula: {func[\\'formula\\']}\")\\n    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\\n    print(\"  Variables:\")\\n    for var in func[\\'variables\\']:\\n        print(f\"    - Name: {var[\\'name\\']}, Range: ({var[\\'low\\']}, {var[\\'high\\']})\")\\n    print()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('physics_equations.csv')\n",
    "\n",
    "functions = []\n",
    "num_vars_per_func = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    formula = row['Formula']\n",
    "    num_vars = row['# variables']\n",
    "    function_details = {\n",
    "        'formula': formula,\n",
    "        'variables': []\n",
    "    }\n",
    "    \n",
    "    for i in range(1, 11):  \n",
    "        v_name = row.get(f'v{i}_name', None)\n",
    "        v_low = row.get(f'v{i}_low', None)\n",
    "        v_high = row.get(f'v{i}_high', None)\n",
    "        \n",
    "        if pd.notna(v_name):\n",
    "            function_details['variables'].append({\n",
    "                'name': v_name,\n",
    "                'low': v_low,\n",
    "                'high': v_high\n",
    "            })\n",
    "    \n",
    "    functions.append(function_details)\n",
    "    num_vars_per_func.append(num_vars)\n",
    "\n",
    "'''for i, func in enumerate(functions):\n",
    "    print(f\"Function {i+1}:\")\n",
    "    print(f\"  Formula: {func['formula']}\")\n",
    "    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\n",
    "    print(\"  Variables:\")\n",
    "    for var in func['variables']:\n",
    "        print(f\"    - Name: {var['name']}, Range: ({var['low']}, {var['high']})\")\n",
    "    print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function(function, sample_size, x, max_vars, device):\n",
    "    sympy_symbols = []\n",
    "    param_tensors = []\n",
    "    \n",
    "    for var in function[\"variables\"]:\n",
    "        sym = sp.symbols(var[\"name\"])\n",
    "        sympy_symbols.append(sym)\n",
    "        min_val, max_val = var[\"low\"], var[\"high\"]\n",
    "        param = (max_val - min_val) * torch.rand(sample_size, 1, device=device) + min_val\n",
    "        param_tensors.append(param)\n",
    "\n",
    "    sympy_symbols.append(sp.symbols('x'))\n",
    "    params = torch.cat(param_tensors, dim=1)\n",
    "    padded_params = F.pad(params, pad=(0, max_vars - params.size(1)))\n",
    "    padded_params = padded_params.expand(sample_size, max_vars)\n",
    "    formula = sp.sympify(function[\"formula\"])\n",
    "    eval_func = sp.lambdify(sympy_symbols, formula, modules=\"numpy\")\n",
    "        \n",
    "    results = []\n",
    "    for xi in x:\n",
    "        input_values = torch.cat([params, xi.expand(sample_size, 1)], dim=1)\n",
    "        results.append(eval_func(*input_values.T))\n",
    "    results = torch.stack(results, dim=1)\n",
    "    \n",
    "    return results, formula, sympy_symbols, padded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "sequence_length = 100\n",
    "num_funcs = 10\n",
    "max_vars = 5\n",
    "\n",
    "x_values = torch.linspace(-1, 1, sequence_length).to(device)\n",
    "hold = []\n",
    "for f in functions[0:10]:\n",
    "    try:\n",
    "        results = generate_function(f, sample_size, x_values, max_vars, device)\n",
    "        hold.append(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing function {f}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = torch.stack([l[0] for l in hold])\n",
    "formulas = [l[1] for l in hold]\n",
    "symbols = [l[2] for l in hold]\n",
    "param_values = torch.stack([l[3] for l in hold])\n",
    "num_params = torch.tensor([len(l[2]) for l in hold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_function(params, symbols, formula, x):\n",
    "    var_values = {symbols[j]: params[:, j] for j in range(len(symbols)-1)}\n",
    "    for key in var_values:\n",
    "        print(f\"{key}: {var_values[key][0]}\")\n",
    "    eval_func = sp.lambdify(symbols, formula, modules=\"numpy\")\n",
    "    results = []\n",
    "    for xi in x:\n",
    "        var_values[symbols[-1]] = xi\n",
    "        np_values = {str(sym): var_values[sym].detach().cpu().numpy() for sym in symbols}\n",
    "        results.append(eval_func(**np_values))\n",
    "    tensor_results = [torch.tensor(r, device=device) for r in results]\n",
    "    return torch.stack(tensor_results, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "params recieved: 0.2693064510822296\n",
      "a: 0.2693064510822296\n",
      "b: 0.8719912767410278\n",
      "c: 0.4585850238800049\n",
      "\n",
      "params recieved: 0.26930344104766846\n",
      "a: 0.26930344104766846\n",
      "b: 0.8719912767410278\n",
      "c: 0.4585850238800049\n",
      "\n",
      "params recieved: 0.26930543780326843\n",
      "a: 0.26930543780326843\n",
      "b: 0.871992290019989\n",
      "c: 0.4585850238800049\n",
      "\n",
      "params recieved: 0.26930543780326843\n",
      "a: 0.26930543780326843\n",
      "b: 0.8719892501831055\n",
      "c: 0.4585850238800049\n",
      "\n",
      "params recieved: 0.26930543780326843\n",
      "a: 0.26930543780326843\n",
      "b: 0.8719912767410278\n",
      "c: 0.45858603715896606\n",
      "\n",
      "params recieved: 0.26930543780326843\n",
      "a: 0.26930543780326843\n",
      "b: 0.8719912767410278\n",
      "c: 0.4585830271244049\n",
      "\n",
      "params recieved: 0.26930543780326843\n",
      "a: 0.26930543780326843\n",
      "b: 0.8719912767410278\n",
      "c: 0.4585850238800049\n",
      "\n",
      "params recieved: 0.26930543780326843\n",
      "a: 0.26930543780326843\n",
      "b: 0.8719912767410278\n",
      "c: 0.4585850238800049\n",
      "\n",
      "params recieved: -0.7356988191604614\n",
      "k: -0.7356988191604614\n",
      "\n",
      "params recieved: -0.735701858997345\n",
      "k: -0.735701858997345\n",
      "\n",
      "params recieved: -0.7356998324394226\n",
      "k: -0.7356998324394226\n",
      "\n",
      "params recieved: -0.7356998324394226\n",
      "k: -0.7356998324394226\n",
      "\n",
      "params recieved: 0.5493261218070984\n",
      "a: 0.5493261218070984\n",
      "\n",
      "params recieved: 0.5493230819702148\n",
      "a: 0.5493230819702148\n",
      "\n",
      "params recieved: 0.5493251085281372\n",
      "a: 0.5493251085281372\n",
      "\n",
      "params recieved: 0.5493251085281372\n",
      "a: 0.5493251085281372\n",
      "\n",
      "params recieved: 0.6065534949302673\n",
      "G: 0.6065534949302673\n",
      "m1: 0.46956658363342285\n",
      "m2: 0.7737636566162109\n",
      "\n",
      "params recieved: 0.6065504550933838\n",
      "G: 0.6065504550933838\n",
      "m1: 0.46956658363342285\n",
      "m2: 0.7737636566162109\n",
      "\n",
      "params recieved: 0.6065524816513062\n",
      "G: 0.6065524816513062\n",
      "m1: 0.46956759691238403\n",
      "m2: 0.7737636566162109\n",
      "\n",
      "params recieved: 0.6065524816513062\n",
      "G: 0.6065524816513062\n",
      "m1: 0.4695645868778229\n",
      "m2: 0.7737636566162109\n",
      "\n",
      "params recieved: 0.6065524816513062\n",
      "G: 0.6065524816513062\n",
      "m1: 0.46956658363342285\n",
      "m2: 0.7737646698951721\n",
      "\n",
      "params recieved: 0.6065524816513062\n",
      "G: 0.6065524816513062\n",
      "m1: 0.46956658363342285\n",
      "m2: 0.7737616300582886\n",
      "\n",
      "params recieved: 0.6065524816513062\n",
      "G: 0.6065524816513062\n",
      "m1: 0.46956658363342285\n",
      "m2: 0.7737636566162109\n",
      "\n",
      "params recieved: 0.6065524816513062\n",
      "G: 0.6065524816513062\n",
      "m1: 0.46956658363342285\n",
      "m2: 0.7737636566162109\n",
      "\n",
      "params recieved: 0.3484147787094116\n",
      "p: 0.3484147787094116\n",
      "g: 0.2603119909763336\n",
      "\n",
      "params recieved: 0.34841176867485046\n",
      "p: 0.34841176867485046\n",
      "g: 0.2603119909763336\n",
      "\n",
      "params recieved: 0.34841376543045044\n",
      "p: 0.34841376543045044\n",
      "g: 0.2603130042552948\n",
      "\n",
      "params recieved: 0.34841376543045044\n",
      "p: 0.34841376543045044\n",
      "g: 0.26030999422073364\n",
      "\n",
      "params recieved: 0.34841376543045044\n",
      "p: 0.34841376543045044\n",
      "g: 0.2603119909763336\n",
      "\n",
      "params recieved: 0.34841376543045044\n",
      "p: 0.34841376543045044\n",
      "g: 0.2603119909763336\n",
      "\n",
      "params recieved: 0.9645872116088867\n",
      "m: 0.9645872116088867\n",
      "\n",
      "params recieved: 0.9645841717720032\n",
      "m: 0.9645841717720032\n",
      "\n",
      "params recieved: 0.9645861983299255\n",
      "m: 0.9645861983299255\n",
      "\n",
      "params recieved: 0.9645861983299255\n",
      "m: 0.9645861983299255\n",
      "\n",
      "params recieved: 0.8286035656929016\n",
      "P: 0.8286035656929016\n",
      "\n",
      "params recieved: 0.8286005258560181\n",
      "P: 0.8286005258560181\n",
      "\n",
      "params recieved: 0.8286025524139404\n",
      "P: 0.8286025524139404\n",
      "\n",
      "params recieved: 0.8286025524139404\n",
      "P: 0.8286025524139404\n",
      "\n",
      "params recieved: 0.802003026008606\n",
      "G: 0.802003026008606\n",
      "M: 0.9770726561546326\n",
      "c: 0.47608986496925354\n",
      "\n",
      "params recieved: 0.8019999861717224\n",
      "G: 0.8019999861717224\n",
      "M: 0.9770726561546326\n",
      "c: 0.47608986496925354\n",
      "\n",
      "params recieved: 0.8020020127296448\n",
      "G: 0.8020020127296448\n",
      "M: 0.9770736694335938\n",
      "c: 0.47608986496925354\n",
      "\n",
      "params recieved: 0.8020020127296448\n",
      "G: 0.8020020127296448\n",
      "M: 0.9770706295967102\n",
      "c: 0.47608986496925354\n",
      "\n",
      "params recieved: 0.8020020127296448\n",
      "G: 0.8020020127296448\n",
      "M: 0.9770726561546326\n",
      "c: 0.4760908782482147\n",
      "\n",
      "params recieved: 0.8020020127296448\n",
      "G: 0.8020020127296448\n",
      "M: 0.9770726561546326\n",
      "c: 0.47608786821365356\n",
      "\n",
      "params recieved: 0.8020020127296448\n",
      "G: 0.8020020127296448\n",
      "M: 0.9770726561546326\n",
      "c: 0.47608986496925354\n",
      "\n",
      "params recieved: 0.8020020127296448\n",
      "G: 0.8020020127296448\n",
      "M: 0.9770726561546326\n",
      "c: 0.47608986496925354\n",
      "\n",
      "params recieved: 0.08859120309352875\n",
      "s: 0.08859120309352875\n",
      "A: 0.2997724413871765\n",
      "\n",
      "params recieved: 0.08858820796012878\n",
      "s: 0.08858820796012878\n",
      "A: 0.2997724413871765\n",
      "\n",
      "params recieved: 0.08859020471572876\n",
      "s: 0.08859020471572876\n",
      "A: 0.2997734546661377\n",
      "\n",
      "params recieved: 0.08859020471572876\n",
      "s: 0.08859020471572876\n",
      "A: 0.29977044463157654\n",
      "\n",
      "params recieved: 0.08859020471572876\n",
      "s: 0.08859020471572876\n",
      "A: 0.2997724413871765\n",
      "\n",
      "params recieved: 0.08859020471572876\n",
      "s: 0.08859020471572876\n",
      "A: 0.2997724413871765\n",
      "\n",
      "params recieved: 0.1306949108839035\n",
      "t: 0.1306949108839035\n",
      "\n",
      "params recieved: 0.13069191575050354\n",
      "t: 0.13069191575050354\n",
      "\n",
      "params recieved: 0.13069391250610352\n",
      "t: 0.13069391250610352\n",
      "\n",
      "params recieved: 0.13069391250610352\n",
      "t: 0.13069391250610352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000, 100, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1e-6\n",
    "derivatives = torch.zeros(num_funcs, sample_size, sequence_length, max_vars)\n",
    "for f in range(num_funcs):\n",
    "    params_f = param_values[f].clone().detach().requires_grad_(True)\n",
    "    for p in range(len(symbols[f])):\n",
    "        perturbed_params_pos = params_f.clone()\n",
    "        perturbed_params_neg = params_f.clone()\n",
    "        perturbed_params_pos[:,p] += epsilon\n",
    "        forward_values = evaluate_function(perturbed_params_pos, symbols[f], formulas[f], x_values)\n",
    "        perturbed_params_neg[:, p] -= 2*epsilon\n",
    "        backward_values = evaluate_function(perturbed_params_neg, symbols[f], formulas[f], x_values)\n",
    "        derivatives[f, :, :, p] = (forward_values - backward_values) / (2 * epsilon)\n",
    "derivatives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000, 100, 5, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians = torch.zeros(num_funcs, sample_size, sequence_length, max_vars, max_vars)\n",
    "for f in range(num_funcs):\n",
    "    params_f = param_values[f].clone().detach().requires_grad_(True)\n",
    "    for j in range(len(symbols[f])):\n",
    "        perturbed_pp = params_f.clone()\n",
    "        perturbed_pn = params_f.clone()\n",
    "        perturbed_np = params_f.clone()\n",
    "        perturbed_nn = params_f.clone()\n",
    "\n",
    "        perturbed_pp[:, j] += epsilon\n",
    "        perturbed_pn[:, j] += epsilon\n",
    "        perturbed_np[:, j] -= epsilon\n",
    "        perturbed_nn[:, j] -= epsilon\n",
    "        for k in range(len(symbols[f])):\n",
    "            perturbed_pp[:, k] += epsilon\n",
    "            perturbed_pn[:, k] -= epsilon\n",
    "            perturbed_np[:, k] += epsilon\n",
    "            perturbed_nn[:, k] -= epsilon\n",
    "\n",
    "            forward_forward = evaluate_function(perturbed_pp, symbols[f], formulas[f], x_values)\n",
    "            forward_backward = evaluate_function(perturbed_pn, symbols[f], formulas[f], x_values)\n",
    "            backward_forward = evaluate_function(perturbed_np, symbols[f], formulas[f], x_values)\n",
    "            backward_backward = evaluate_function(perturbed_nn, symbols[f], formulas[f], x_values)\n",
    "            hessians[f, :, :, j, k] = (forward_forward - forward_backward - backward_forward + backward_backward) / (4 * epsilon **2)\n",
    "hessians.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial 0: 0.3012508451938629\n",
      "forward 0: 0.30135083198547363\n",
      "m: 0.30135083198547363\n",
      "eval forward 0: 0.15067541599273682\n",
      "\n",
      "backward 0: 0.3011508584022522\n",
      "m: 0.3011508584022522\n",
      "eval backward 0: 0.1505754292011261\n",
      "\n",
      "Derivative 0: 0.49993395805358887\n",
      "\n",
      "Initial 1: 0.0\n",
      "forward 1: 9.999999747378752e-05\n",
      "m: 0.3012508451938629\n",
      "eval forward 1: 0.15062542259693146\n",
      "\n",
      "backward 1: -9.999999747378752e-05\n",
      "m: 0.3012508451938629\n",
      "eval backward 1: 0.15062542259693146\n",
      "\n",
      "Derivative 1: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000, 100, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem with params revieced!\n",
    "epsilon = 1e-4\n",
    "f = 5\n",
    "tester = torch.zeros(num_funcs, sample_size, sequence_length, max_vars)\n",
    "parami = param_values[f].clone().detach().requires_grad_(True)\n",
    "for p in range(len(symbols[f])):\n",
    "    plus = parami.clone()\n",
    "    minus = parami.clone()\n",
    "\n",
    "    print(f\"\\nInitial {p}: {plus[0, p]}\")\n",
    "    plus[:,p] += epsilon\n",
    "    print(f\"forward {p}: {plus[0, p]}\")\n",
    "    forward_values = evaluate_function(plus, symbols[f], formulas[f], x_values)\n",
    "    print(f\"eval forward {p}: {forward_values[0, 0]}\")\n",
    "    minus[:, p] -= epsilon\n",
    "    print(f\"\\nbackward {p}: {minus[0, p]}\")\n",
    "    backward_values = evaluate_function(minus, symbols[f], formulas[f], x_values)\n",
    "    print(f\"eval backward {p}: {backward_values[0, 0]}\")\n",
    "    tester[f, :, :, p] = (forward_values - backward_values) / (2 * epsilon)\n",
    "    print(f\"\\nDerivative {p}: {tester[f, 0, 0, p]}\")\n",
    "tester.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4999, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester[f, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.8990, device='cuda:4'),\n",
       " m*x**2/2,\n",
       " [m, x],\n",
       " tensor([0.3013, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:4'),\n",
       " tensor(0.1506, device='cuda:4'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values[f], formulas[f], symbols[f], param_values[f, 0], y_values[f, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives(parameters, func, symbols, formula, x, epsilon=1e-6):\n",
    "    batch_size = parameters.shape[0]\n",
    "    num_params = len(symbols)\n",
    "    gradients = torch.zeros(batch_size, num_params, x.shape[0])\n",
    "    print(parameters.shape)\n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        print(param_tensor.shape)\n",
    "        for j in range(num_params):\n",
    "            perturbed_params_pos = param_tensor.clone()\n",
    "            perturbed_params_neg = param_tensor.clone()\n",
    "            print(perturbed_params_pos.shape)\n",
    "            perturbed_params_pos[j] += epsilon\n",
    "            forward_values = func(perturbed_params_pos, symbols, formula, x)\n",
    "            print(forward_values.shape)\n",
    "            perturbed_params_neg[j] -= epsilon\n",
    "            backward_values = func(perturbed_params_neg, symbols, formula, x)\n",
    "            \n",
    "            gradients[i, j] = (forward_values - backward_values) / (2 * epsilon)\n",
    "    \n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessians(parameters, func, symbols, formula, epsilon=1e-6):\n",
    "    batch_size = parameters.shape[0]\n",
    "    num_params = parameters.shape[2]\n",
    "    hessian = torch.zeros(batch_size, num_params, num_params)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for j in range(num_params):\n",
    "            for k in range(j, num_params):\n",
    "                perturbed_params_pp = param_tensor.clone()\n",
    "                perturbed_params_pp[0, j, 0] += epsilon\n",
    "                perturbed_params_pp[0, k, 0] += epsilon\n",
    "                ff_value = func(perturbed_params_pp, symbols, formula)\n",
    "\n",
    "                perturbed_params_nn = param_tensor.clone()\n",
    "                perturbed_params_nn[0, j, 0] -= epsilon\n",
    "                perturbed_params_nn[0, k, 0] -= epsilon\n",
    "                bb_value = func(perturbed_params_nn, symbols, formula)\n",
    "\n",
    "                if j == k:\n",
    "                    center_value = func(param_tensor, symbols, formula)\n",
    "                    hessian[i, j, k] = (ff_value - 2 * center_value + bb_value) / (epsilon ** 2)\n",
    "                else:\n",
    "                    perturbed_params_pn = param_tensor.clone()\n",
    "                    perturbed_params_pn[0, j, 0] += epsilon\n",
    "                    perturbed_params_pn[0, k, 0] -= epsilon\n",
    "                    fb_value = func(perturbed_params_pn, symbols, formula)\n",
    "\n",
    "                    perturbed_params_np = param_tensor.clone()\n",
    "                    perturbed_params_np[0, j, 0] -= epsilon\n",
    "                    perturbed_params_np[0, k, 0] += epsilon\n",
    "                    bf_value = func(perturbed_params_np, symbols, formula)\n",
    "\n",
    "                    hessian[i, j, k] = (ff_value - fb_value - bf_value + bb_value) / (4 * epsilon ** 2)\n",
    "                    hessian[i, k, j] = hessian[i, j, k]\n",
    "\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 5]), [a, b, c, x], a*x**2 + b*x + c)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_values[0].shape, symbols_hold[0], formulas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def compute_hessians(parameters, func, symbols, formula, epsilon=1e-6): #need to fix\n",
    "    batch_size = parameters.shape[0]\n",
    "    max_num_params = parameters.shape[2]\n",
    "    hessians = torch.zeros((batch_size, max_num_params, max_num_params))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for j in range(max_num_params):\n",
    "            for k in range(max_num_params):\n",
    "                # Perturb j-th and k-th parameters\n",
    "                perturbed_params = param_tensor.clone()\n",
    "                \n",
    "                # Compute f(x + epsilon * e_j + epsilon * e_k)\n",
    "                perturbed_params_jk = perturbed_params.clone()\n",
    "                perturbed_params_jk[:, j, :] += epsilon\n",
    "                perturbed_params_jk[:, k, :] += epsilon\n",
    "                f_plus_plus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x + epsilon * e_j - epsilon * e_k)\n",
    "                perturbed_params_jk[:, k, :] -= 2 * epsilon\n",
    "                f_plus_minus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x - epsilon * e_j + epsilon * e_k)\n",
    "                perturbed_params_jk[:, j, :] -= 2 * epsilon\n",
    "                perturbed_params_jk[:, k, :] += 2 * epsilon\n",
    "                f_minus_plus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x - epsilon * e_j - epsilon * e_k)\n",
    "                perturbed_params_jk[:, k, :] -= 2 * epsilon\n",
    "                f_minus_minus = func(perturbed_params_jk, symbols, formula)\n",
    "                hessians[i, j, k] = (f_plus_plus - f_plus_minus - f_minus_plus + f_minus_minus) / (4 * epsilon**2)\n",
    "    \n",
    "    return hessians'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 81]), torch.Size([10000, 81]), torch.Size([10000, 81]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_result = torch.flatten(torch.stack(y_values).unsqueeze(2), start_dim=0, end_dim=1)\n",
    "\n",
    "max_der = max(d.size(1) for d in derivatives)\n",
    "padded_ders = []\n",
    "for d in derivatives:\n",
    "    padded_tensor = F.pad(d, pad=(0, max_der - d.size(1)))\n",
    "    padded_ders.append(padded_tensor)\n",
    "flat_der = torch.flatten(torch.stack(padded_ders), start_dim=0, end_dim=1)\n",
    "\n",
    "max_hess = max_der**2\n",
    "padded_hess = []\n",
    "for h in hessians:\n",
    "    h = torch.flatten(h, start_dim=1)\n",
    "    padded_tensor = F.pad(h, pad=(0, max_hess - h.size(1)))\n",
    "    padded_hess.append(padded_tensor)\n",
    "flat_hess = torch.flatten(torch.stack(padded_hess), start_dim=0, end_dim=1)\n",
    "\n",
    "flat_der = F.pad(flat_der, (0, flat_hess.size(-1) - flat_der.size(-1)))\n",
    "flat_result = F.pad(flat_result, (0, flat_hess.size(-1) - flat_result.size(-1)))\n",
    "\n",
    "flat_result.shape, flat_der.shape, flat_hess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_params = torch.repeat_interleave(num_params, repeats=sample_size)\n",
    "y_values = torch.flatten(y_values, end_dim=1)\n",
    "param_values = torch.flatten(param_values, end_dim=1)\n",
    "formulas = np.array([[formula for _ in range(1000)] for formula in formulas]).flatten()\n",
    "symbols = []\n",
    "for s in symbols_hold:\n",
    "    for _ in range(sample_size):\n",
    "        symbols.append(s)\n",
    "\n",
    "y_values.shape, param_values.shape, num_params.shape, formulas.shape, len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'flattened_data': torch.stack([flat_result, flat_der, flat_hess], dim=2),\n",
    "    'results': y_values,\n",
    "    'formulas': hold_formulas,\n",
    "    'symbols': hold_symbols,\n",
    "    'params': param_values,\n",
    "    'num_params': num_params,\n",
    "}, 'hold_data.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
