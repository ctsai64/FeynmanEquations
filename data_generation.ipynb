{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, func in enumerate(functions):\\n    print(f\"Function {i+1}:\")\\n    print(f\"  Formula: {func[\\'formula\\']}\")\\n    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\\n    print(\"  Variables:\")\\n    for var in func[\\'variables\\']:\\n        print(f\"    - Name: {var[\\'name\\']}, Range: ({var[\\'low\\']}, {var[\\'high\\']})\")\\n    print()'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('physics_equations.csv')\n",
    "\n",
    "functions = []\n",
    "num_vars_per_func = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    formula = row['Formula']\n",
    "    num_vars = row['# variables']\n",
    "    function_details = {\n",
    "        'formula': formula,\n",
    "        'variables': []\n",
    "    }\n",
    "    \n",
    "    for i in range(1, 11):  \n",
    "        v_name = row.get(f'v{i}_name', None)\n",
    "        v_low = row.get(f'v{i}_low', None)\n",
    "        v_high = row.get(f'v{i}_high', None)\n",
    "        \n",
    "        if pd.notna(v_name):\n",
    "            function_details['variables'].append({\n",
    "                'name': v_name,\n",
    "                'low': v_low,\n",
    "                'high': v_high\n",
    "            })\n",
    "    \n",
    "    functions.append(function_details)\n",
    "    num_vars_per_func.append(num_vars)\n",
    "\n",
    "'''for i, func in enumerate(functions):\n",
    "    print(f\"Function {i+1}:\")\n",
    "    print(f\"  Formula: {func['formula']}\")\n",
    "    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\n",
    "    print(\"  Variables:\")\n",
    "    for var in func['variables']:\n",
    "        print(f\"    - Name: {var['name']}, Range: ({var['low']}, {var['high']})\")\n",
    "    print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function(function, sample_size, x, max_vars, device):\n",
    "    sympy_symbols = []\n",
    "    param_tensors = []\n",
    "    \n",
    "    for var in function[\"variables\"]:\n",
    "        sym = sp.symbols(var[\"name\"])\n",
    "        sympy_symbols.append(sym)\n",
    "        min_val, max_val = var[\"low\"], var[\"high\"]\n",
    "        param = (max_val - min_val) * torch.rand(sample_size, 1, device=device) + min_val\n",
    "        param_tensors.append(param)\n",
    "\n",
    "    sympy_symbols.append(sp.symbols('x'))\n",
    "    symbols = np.array(sympy_symbols)\n",
    "    symbols = np.pad(symbols, (0, max_vars - len(symbols)))\n",
    "    params = torch.cat(param_tensors, dim=1)\n",
    "    padded_params = F.pad(params, pad=(0, max_vars - params.size(1)))\n",
    "    padded_params = padded_params.expand(sample_size, max_vars)\n",
    "    formula = sp.sympify(function[\"formula\"])\n",
    "    eval_func = sp.lambdify(sympy_symbols, formula, modules=\"numpy\")\n",
    "        \n",
    "    results = []\n",
    "    for xi in x:\n",
    "        input_values = torch.cat([params, xi.expand(sample_size, 1)], dim=1)\n",
    "        results.append(eval_func(*input_values.T))\n",
    "    results = torch.stack(results, dim=1)\n",
    "    \n",
    "    return results, formula, symbols, padded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "sequence_length = 100\n",
    "num_funcs = 10\n",
    "max_vars = 5\n",
    "\n",
    "x_values = torch.linspace(-1, 1, sequence_length).to(device)\n",
    "hold = []\n",
    "for f in functions[0:10]:\n",
    "    try:\n",
    "        results = generate_function(f, sample_size, x_values, max_vars, device)\n",
    "        hold.append(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing function {f}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 100]),\n",
       " torch.Size([10000, 5]),\n",
       " torch.Size([10000]),\n",
       " (10000,),\n",
       " (10000, 5))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values = torch.stack([l[0] for l in hold])\n",
    "formulas = [l[1] for l in hold]\n",
    "symbols = [l[2] for l in hold]\n",
    "param_values = torch.stack([l[3] for l in hold])\n",
    "num_params = torch.tensor([len(l[2]) for l in hold])\n",
    "\n",
    "num_params = torch.repeat_interleave(num_params, repeats=sample_size)\n",
    "y_values = torch.flatten(y_values, end_dim=1)\n",
    "param_values = torch.flatten(param_values, end_dim=1)\n",
    "formulas = np.array([[formula for _ in range(1000)] for formula in formulas]).flatten()\n",
    "symbols = np.array([[symbol for _ in range(1000)] for symbol in symbols])\n",
    "symbols = symbols.reshape(num_funcs*sample_size, max_vars)\n",
    "\n",
    "y_values.shape, param_values.shape, num_params.shape, formulas.shape, symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4813+0.j, device='cuda:4'),\n",
       " tensor([0.9626, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:4'),\n",
       " tensor(5),\n",
       " a*x**2/2,\n",
       " array([a, x, np.int64(0), np.int64(0), np.int64(0)], dtype=object))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values[2000][0], param_values[2000], num_params[2000], formulas[2000], symbols[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_function(params, symbols, formula, x):\n",
    "    eval_func = sp.lambdify(symbols, formula, modules=\"numpy\")\n",
    "    sample_size = params.shape[0]\n",
    "    results = []\n",
    "    for xi in x:\n",
    "        print(params)\n",
    "        params_2d = params.view(sample_size, -1)\n",
    "        xi_expanded = xi.expand(sample_size, 1)\n",
    "        input_values = torch.cat([params_2d, xi_expanded], dim=1)        \n",
    "        print(input_values)\n",
    "        results.append(eval_func(*input_values.T))\n",
    "    return torch.stack(results, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives(parameters, func, symbols, formula, x, epsilon=1e-6):\n",
    "    batch_size = parameters.shape[0]\n",
    "    num_params = parameters.shape[1]\n",
    "    gradients = torch.zeros(batch_size, num_params)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for j in range(num_params):\n",
    "            perturbed_params_pos = param_tensor.clone()\n",
    "            perturbed_params_neg = param_tensor.clone()\n",
    "            \n",
    "            perturbed_params_pos[j] += epsilon\n",
    "            print(perturbed_params_pos.shape)\n",
    "            forward_values = func(perturbed_params_pos, symbols, formula, x)\n",
    "            \n",
    "            perturbed_params_neg[j] -= epsilon\n",
    "            backward_values = func(perturbed_params_neg, symbols, formula, x)\n",
    "            \n",
    "            gradients[i, j] = (forward_values - backward_values) / (2 * epsilon)\n",
    "    \n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessians(parameters, func, symbols, formula, epsilon=1e-6):\n",
    "    batch_size = parameters.shape[0]\n",
    "    num_params = parameters.shape[2]\n",
    "    hessian = torch.zeros(batch_size, num_params, num_params)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for j in range(num_params):\n",
    "            for k in range(j, num_params):\n",
    "                perturbed_params_pp = param_tensor.clone()\n",
    "                perturbed_params_pp[0, j, 0] += epsilon\n",
    "                perturbed_params_pp[0, k, 0] += epsilon\n",
    "                ff_value = func(perturbed_params_pp, symbols, formula)\n",
    "\n",
    "                perturbed_params_nn = param_tensor.clone()\n",
    "                perturbed_params_nn[0, j, 0] -= epsilon\n",
    "                perturbed_params_nn[0, k, 0] -= epsilon\n",
    "                bb_value = func(perturbed_params_nn, symbols, formula)\n",
    "\n",
    "                if j == k:\n",
    "                    center_value = func(param_tensor, symbols, formula)\n",
    "                    hessian[i, j, k] = (ff_value - 2 * center_value + bb_value) / (epsilon ** 2)\n",
    "                else:\n",
    "                    perturbed_params_pn = param_tensor.clone()\n",
    "                    perturbed_params_pn[0, j, 0] += epsilon\n",
    "                    perturbed_params_pn[0, k, 0] -= epsilon\n",
    "                    fb_value = func(perturbed_params_pn, symbols, formula)\n",
    "\n",
    "                    perturbed_params_np = param_tensor.clone()\n",
    "                    perturbed_params_np[0, j, 0] -= epsilon\n",
    "                    perturbed_params_np[0, k, 0] += epsilon\n",
    "                    bf_value = func(perturbed_params_np, symbols, formula)\n",
    "\n",
    "                    hessian[i, j, k] = (ff_value - fb_value - bf_value + bb_value) / (4 * epsilon ** 2)\n",
    "                    hessian[i, k, j] = hessian[i, j, k]\n",
    "\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1., device='cuda:4')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([ 0.5163, -0.9938, -0.9851], device='cuda:4', grad_fn=<CopySlices>)\n",
      "tensor([[ 0.5163, -1.0000],\n",
      "        [-0.9938, -1.0000],\n",
      "        [-0.9851, -1.0000]], device='cuda:4', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_lambdifygenerated() missing 2 required positional arguments: 'c' and 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m derivative_test \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhold_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhold_symbols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhold_formulas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m hessian_test \u001b[38;5;241m=\u001b[39m compute_hessians(hold_params[\u001b[38;5;241m0\u001b[39m], evaluate_function, hold_symbols[\u001b[38;5;241m0\u001b[39m], hold_formulas[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mcompute_derivatives\u001b[0;34m(parameters, func, symbols, formula, x, epsilon)\u001b[0m\n\u001b[1;32m     13\u001b[0m perturbed_params_pos[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(perturbed_params_pos\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 15\u001b[0m forward_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_params_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m perturbed_params_neg[j] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon\n\u001b[1;32m     18\u001b[0m backward_values \u001b[38;5;241m=\u001b[39m func(perturbed_params_neg, symbols, formula, x)\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mevaluate_function\u001b[0;34m(params, symbols, formula, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     input_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([params_2d, xi_expanded], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)        \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(input_values)\n\u001b[0;32m---> 11\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43meval_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(results, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: _lambdifygenerated() missing 2 required positional arguments: 'c' and 'x'"
     ]
    }
   ],
   "source": [
    "derivative_test = compute_derivatives(param_values[0], evaluate_function, hold_symbols[0], hold_formulas[0], x_values)\n",
    "hessian_test = compute_hessians(param_values[0], evaluate_function, hold_symbols[0], hold_formulas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def compute_hessians(parameters, func, symbols, formula, epsilon=1e-6): #need to fix\n",
    "    batch_size = parameters.shape[0]\n",
    "    max_num_params = parameters.shape[2]\n",
    "    hessians = torch.zeros((batch_size, max_num_params, max_num_params))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for j in range(max_num_params):\n",
    "            for k in range(max_num_params):\n",
    "                # Perturb j-th and k-th parameters\n",
    "                perturbed_params = param_tensor.clone()\n",
    "                \n",
    "                # Compute f(x + epsilon * e_j + epsilon * e_k)\n",
    "                perturbed_params_jk = perturbed_params.clone()\n",
    "                perturbed_params_jk[:, j, :] += epsilon\n",
    "                perturbed_params_jk[:, k, :] += epsilon\n",
    "                f_plus_plus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x + epsilon * e_j - epsilon * e_k)\n",
    "                perturbed_params_jk[:, k, :] -= 2 * epsilon\n",
    "                f_plus_minus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x - epsilon * e_j + epsilon * e_k)\n",
    "                perturbed_params_jk[:, j, :] -= 2 * epsilon\n",
    "                perturbed_params_jk[:, k, :] += 2 * epsilon\n",
    "                f_minus_plus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x - epsilon * e_j - epsilon * e_k)\n",
    "                perturbed_params_jk[:, k, :] -= 2 * epsilon\n",
    "                f_minus_minus = func(perturbed_params_jk, symbols, formula)\n",
    "                hessians[i, j, k] = (f_plus_plus - f_plus_minus - f_minus_plus + f_minus_minus) / (4 * epsilon**2)\n",
    "    \n",
    "    return hessians'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = [compute_derivative(param_values[i], evaluate_function, hold_symbols[i], hold_formulas[i]) for i in range(len(param_values))]\n",
    "hessians = [compute_hessians(param_values[i], evaluate_function, hold_symbols[i], hold_formulas[i]) for i in range(len(param_values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 81]), torch.Size([10000, 81]), torch.Size([10000, 81]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_result = torch.flatten(torch.stack(y_values).unsqueeze(2), start_dim=0, end_dim=1)\n",
    "\n",
    "max_der = max(d.size(1) for d in derivatives)\n",
    "padded_ders = []\n",
    "for d in derivatives:\n",
    "    padded_tensor = F.pad(d, pad=(0, max_der - d.size(1)))\n",
    "    padded_ders.append(padded_tensor)\n",
    "flat_der = torch.flatten(torch.stack(padded_ders), start_dim=0, end_dim=1)\n",
    "\n",
    "max_hess = max_der**2\n",
    "padded_hess = []\n",
    "for h in hessians:\n",
    "    h = torch.flatten(h, start_dim=1)\n",
    "    padded_tensor = F.pad(h, pad=(0, max_hess - h.size(1)))\n",
    "    padded_hess.append(padded_tensor)\n",
    "flat_hess = torch.flatten(torch.stack(padded_hess), start_dim=0, end_dim=1)\n",
    "\n",
    "flat_der = F.pad(flat_der, (0, flat_hess.size(-1) - flat_der.size(-1)))\n",
    "flat_result = F.pad(flat_result, (0, flat_hess.size(-1) - flat_result.size(-1)))\n",
    "\n",
    "flat_result.shape, flat_der.shape, flat_hess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'flattened_data': torch.stack([flat_result, flat_der, flat_hess], dim=2),\n",
    "    'results': y_values,\n",
    "    'formulas': hold_formulas,\n",
    "    'symbols': hold_symbols,\n",
    "    'params': param_values,\n",
    "    'num_params': num_params,\n",
    "}, 'hold_data.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
