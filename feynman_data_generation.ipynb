{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, func in enumerate(functions):\\n    print(f\"Function {i+1}:\")\\n    print(f\"  Formula: {func[\\'formula\\']}\")\\n    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\\n    print(\"  Variables:\")\\n    for var in func[\\'variables\\']:\\n        print(f\"    - Name: {var[\\'name\\']}, Range: ({var[\\'low\\']}, {var[\\'high\\']})\")\\n    print()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('FeynmanEquations.csv')\n",
    "\n",
    "functions = []\n",
    "num_vars_per_func = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    formula = row['Formula']\n",
    "    num_vars = row['# variables']\n",
    "    function_details = {\n",
    "        'formula': formula,\n",
    "        'variables': []\n",
    "    }\n",
    "    \n",
    "    for i in range(1, 11):  \n",
    "        v_name = row.get(f'v{i}_name', None)\n",
    "        v_low = row.get(f'v{i}_low', None)\n",
    "        v_high = row.get(f'v{i}_high', None)\n",
    "        \n",
    "        if pd.notna(v_name):\n",
    "            function_details['variables'].append({\n",
    "                'name': v_name,\n",
    "                'low': v_low,\n",
    "                'high': v_high\n",
    "            })\n",
    "    \n",
    "    functions.append(function_details)\n",
    "    num_vars_per_func.append(num_vars)\n",
    "\n",
    "'''for i, func in enumerate(functions):\n",
    "    print(f\"Function {i+1}:\")\n",
    "    print(f\"  Formula: {func['formula']}\")\n",
    "    print(f\"  Number of Variables: {num_vars_per_func[i]}\")\n",
    "    print(\"  Variables:\")\n",
    "    for var in func['variables']:\n",
    "        print(f\"    - Name: {var['name']}, Range: ({var['low']}, {var['high']})\")\n",
    "    print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function(function, sample_size, device):\n",
    "    hold = []\n",
    "    sympy_symbols = []\n",
    "    \n",
    "    for var in function[\"variables\"]:\n",
    "        sym = sp.symbols(var[\"name\"])\n",
    "        sympy_symbols.append(sym)\n",
    "        min_val = var[\"low\"]\n",
    "        max_val = var[\"high\"]\n",
    "        v = (max_val - min_val) * torch.rand(sample_size, 1, 1) + min_val\n",
    "        hold.append(v)\n",
    "    \n",
    "    params = torch.stack(hold)\n",
    "    params = torch.atleast_2d(params)\n",
    "    params = torch.transpose(params, 0, 1)\n",
    "    params = torch.transpose(params, 1, 2)\n",
    "    params = params.to(device)\n",
    "\n",
    "    formula = sp.sympify(function[\"formula\"])\n",
    "    \n",
    "    results = []\n",
    "    for i in range(sample_size):\n",
    "        var_values = {sympy_symbols[j]: params[i, 0, j].item() for j in range(len(sympy_symbols))}\n",
    "        evaluated = formula.subs(var_values)\n",
    "        results.append(float(evaluated))\n",
    "    \n",
    "    return results, formula, sympy_symbols, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "hold = []\n",
    "for f in functions[0:10]:\n",
    "    try:\n",
    "        results = generate_function(f, sample_size, device)\n",
    "        hold.append(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing function {f}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_data = [torch.tensor(l[0]) for l in hold]\n",
    "hold_formulas = [l[1] for l in hold]\n",
    "hold_symbols = [l[2] for l in hold]\n",
    "hold_params = [l[3] for l in hold]\n",
    "hold_num_params = [len(l[2]) for l in hold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivative(parameters, func, symbols, formula, epsilon=1e-6):\n",
    "    batch_size = parameters.shape[0]\n",
    "    num_params = parameters.shape[2]\n",
    "    gradients = torch.zeros(batch_size, num_params)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for j in range(num_params):\n",
    "            perturbed_params_pos = param_tensor.clone()\n",
    "            perturbed_params_neg = param_tensor.clone()\n",
    "            \n",
    "            perturbed_params_pos[0, j, 0] += epsilon\n",
    "            forward_value = func(perturbed_params_pos, symbols, formula)\n",
    "            \n",
    "            perturbed_params_neg[0, j, 0] -= epsilon\n",
    "            backward_value = func(perturbed_params_neg, symbols, formula)\n",
    "            \n",
    "            gradients[i, j] = (forward_value - backward_value) / (2 * epsilon)\n",
    "    \n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessians(parameters, func, symbols, formula, epsilon=1e-6): #need to fix\n",
    "    batch_size = parameters.shape[0]\n",
    "    max_num_params = parameters.shape[2]\n",
    "    hessians = torch.zeros((batch_size, max_num_params, max_num_params))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        param_tensor = parameters[i].clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for j in range(max_num_params):\n",
    "            for k in range(max_num_params):\n",
    "                # Perturb j-th and k-th parameters\n",
    "                perturbed_params = param_tensor.clone()\n",
    "                \n",
    "                # Compute f(x + epsilon * e_j + epsilon * e_k)\n",
    "                perturbed_params_jk = perturbed_params.clone()\n",
    "                perturbed_params_jk[:, j, :] += epsilon\n",
    "                perturbed_params_jk[:, k, :] += epsilon\n",
    "                f_plus_plus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x + epsilon * e_j - epsilon * e_k)\n",
    "                perturbed_params_jk[:, k, :] -= 2 * epsilon\n",
    "                f_plus_minus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x - epsilon * e_j + epsilon * e_k)\n",
    "                perturbed_params_jk[:, j, :] -= 2 * epsilon\n",
    "                perturbed_params_jk[:, k, :] += 2 * epsilon\n",
    "                f_minus_plus = func(perturbed_params_jk, symbols, formula)\n",
    "                \n",
    "                # Compute f(x - epsilon * e_j - epsilon * e_k)\n",
    "                perturbed_params_jk[:, k, :] -= 2 * epsilon\n",
    "                f_minus_minus = func(perturbed_params_jk, symbols, formula)\n",
    "                hessians[i, j, k] = (f_plus_plus - f_plus_minus - f_minus_plus + f_minus_minus) / (4 * epsilon**2)\n",
    "    \n",
    "    return hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_function(params, symbols, formula):\n",
    "    if params.shape[0] != 1:\n",
    "        var_values = {symbols[j]: params[j].item() for j in range(len(symbols))}\n",
    "    else:\n",
    "        var_values = {symbols[j]: params[:, j, :].item() for j in range(len(symbols))}\n",
    "    evaluated = formula.subs(var_values)\n",
    "    return float(evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = [compute_derivative(hold_params[i], evaluate_function, hold_symbols[i], hold_formulas[i]) for i in range(len(hold_params))]\n",
    "hessians = [compute_hessians(hold_params[i], evaluate_function, hold_symbols[i], hold_formulas[i]) for i in range(len(hold_params))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 81]), torch.Size([10000, 81]), torch.Size([10000, 81]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_result = torch.flatten(torch.stack(hold_data).unsqueeze(2), start_dim=0, end_dim=1)\n",
    "\n",
    "max_der = max(d.size(1) for d in derivatives)\n",
    "padded_ders = []\n",
    "for d in derivatives:\n",
    "    padded_tensor = F.pad(d, pad=(0, max_der - d.size(1)))\n",
    "    padded_ders.append(padded_tensor)\n",
    "flat_der = torch.flatten(torch.stack(padded_ders), start_dim=0, end_dim=1)\n",
    "\n",
    "max_hess = max_der**2\n",
    "padded_hess = []\n",
    "for h in hessians:\n",
    "    h = torch.flatten(h, start_dim=1)\n",
    "    padded_tensor = F.pad(h, pad=(0, max_hess - h.size(1)))\n",
    "    padded_hess.append(padded_tensor)\n",
    "flat_hess = torch.flatten(torch.stack(padded_hess), start_dim=0, end_dim=1)\n",
    "\n",
    "flat_der = F.pad(flat_der, (0, flat_hess.size(-1) - flat_der.size(-1)))\n",
    "flat_result = F.pad(flat_result, (0, flat_hess.size(-1) - flat_result.size(-1)))\n",
    "\n",
    "flat_result.shape, flat_der.shape, flat_hess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'flattened_data': torch.stack([flat_result, flat_der, flat_hess], dim=2),\n",
    "    'results': hold_data,\n",
    "    'formulas': hold_formulas,\n",
    "    'symbols': hold_symbols,\n",
    "    'params': hold_params,\n",
    "    'num_params': hold_num_params,\n",
    "}, 'hold_data.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
