{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2917641/1158532762.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load('hold_data.pth')\n",
      "/tmp/ipykernel_2917641/1158532762.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hessians = torch.load('hold_other.pth')['hessians'].to(device)\n"
     ]
    }
   ],
   "source": [
    "loaded_data = torch.load('hold_data.pth')\n",
    "\n",
    "x_values = loaded_data['x_values'].to(device)\n",
    "y_values = loaded_data['y_values'].to(device)\n",
    "derivatives = loaded_data['derivatives'].to(device)\n",
    "params = loaded_data['param_values'].to(device)\n",
    "functions = loaded_data['formulas']\n",
    "symbols = loaded_data['symbols']\n",
    "num_params = loaded_data['num_params'].to(device)\n",
    "hessians = torch.load('hold_other.pth')['hessians'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_values: torch.Size([100])\n",
      "y_values: torch.Size([10000, 100])\n",
      "derivatives: torch.Size([10000, 100, 5])\n",
      "hessians: torch.Size([10000, 100, 25])\n",
      "param_values: torch.Size([10000, 5])\n",
      "formulas: 10\n",
      "symbols: 10\n",
      "num_params: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_values: {x_values.shape}\")\n",
    "print(f\"y_values: {y_values.shape}\")\n",
    "print(f\"derivatives: {derivatives.shape}\")\n",
    "print(f\"hessians: {hessians.shape}\")\n",
    "print(f\"param_values: {params.shape}\")\n",
    "print(f\"formulas: {len(functions)}\")\n",
    "print(f\"symbols: {len(symbols)}\")\n",
    "print(f\"num_params: {num_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hessians.flatten(1,2)\n",
    "d = derivatives.flatten(1,2)\n",
    "d = F.pad(d, (0,h.shape[1]-d.shape[1]))\n",
    "y = F.pad(y_values, (0,h.shape[1]-y_values.shape[1]))\n",
    "full_data = torch.stack([y,d,h], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Func_Channels(nn.Module):\n",
    "    def __init__(self, functions, num_params, x_data, input_channels, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.functions = functions\n",
    "        self.x_data = x_data.to(self.device)\n",
    "        self.input_channels = input_channels\n",
    "        self.num_params = num_params\n",
    "        self.max_params = max(num_params)\n",
    "        self.total_params = sum(self.num_params)\n",
    "        self.symbols = symbols\n",
    "        self.epsilon = 1e-4\n",
    "\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.input_channels, out_channels=8, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(64)\n",
    "        )\n",
    "\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(32, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(16),\n",
    "            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(8),\n",
    "            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(4),\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(28, 128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, self.total_params),\n",
    "        )\n",
    "\n",
    "    def evaluate(self, params, index):\n",
    "        symbols = self.symbols[index]\n",
    "        formula = self.functions[index]\n",
    "        x = self.x_data\n",
    "        var_values = {str(symbols[j]): params[:, j] for j in range(len(symbols)-1)}\n",
    "        eval_func = sp.lambdify(symbols, formula, modules=\"numpy\")\n",
    "        #results = []\n",
    "        #for xi in x:\n",
    "        var_values[str(symbols[-1])] = x.unsqueeze(1)\n",
    "            #np_values = {str(sym): var_values[sym].detach().cpu().numpy() for sym in symbols}\n",
    "        results = eval_func(**var_values)\n",
    "        #results.append(eval_func(**var_values))\n",
    "        #tensor_results = [torch.tensor(r, device=device) for r in results]\n",
    "        return results.swapaxes(0,1)\n",
    "    \n",
    "    def derivative(self, params, index):\n",
    "        derivatives = torch.zeros((params.shape[0], self.x_data.shape[0], self.max_params))\n",
    "        params_n = params.clone().detach().requires_grad_(True)\n",
    "        for p in range(len(symbols[index])-1):\n",
    "            plus = params_n.clone()\n",
    "            minus = params_n.clone()\n",
    "            plus[:,p] += self.epsilon\n",
    "            forward_values = self.evaluate(plus, index)\n",
    "            minus[:, p] -= self.epsilon\n",
    "            backward_values = self.evaluate(minus, index)\n",
    "            derivatives[:, :, p] = (forward_values - backward_values) / (2 * self.epsilon)\n",
    "        return derivatives.flatten(1,2)\n",
    "    \n",
    "    '''def derivative(self, params, index):\n",
    "        params.requires_grad_(True)\n",
    "        y = self.evaluate(params, index)\n",
    "        d = torch.autograd.grad(y.sum(), params, create_graph=True)[0]\n",
    "        d = F.pad(d, (0, self.max_params - d.shape[1]))\n",
    "        return d'''\n",
    "\n",
    "    '''def hessian(self, params, index):\n",
    "        params.requires_grad_(True)\n",
    "        y = self.evaluate(params, index)\n",
    "        grad = torch.autograd.grad(y.sum(), params, create_graph=True)[0]\n",
    "        return torch.stack([torch.autograd.grad(g, params, retain_graph=True)[0] for g in grad.flatten()]).reshape(params.shape + params.shape)'''\n",
    "\n",
    "\n",
    "    def hessian(self, params, index):\n",
    "        hessians = torch.zeros((params.shape[0], self.x_data.shape[0], self.max_params, self.max_params))\n",
    "        params_f = params.clone().detach().requires_grad_(True)\n",
    "        for j in range(len(symbols[index])-1):\n",
    "            for k in range(len(symbols[index])-1):\n",
    "                plus_plus = params_f.clone()\n",
    "                plus_minus = params_f.clone()\n",
    "                minus_plus = params_f.clone()\n",
    "                minus_minus = params_f.clone()\n",
    "\n",
    "                plus_plus[:, j] += self.epsilon\n",
    "                plus_plus[:, k] += self.epsilon\n",
    "\n",
    "                plus_minus[:, j] += self.epsilon\n",
    "                plus_minus[:, k] -= self.epsilon\n",
    "\n",
    "                minus_plus[:, j] -= self.epsilon\n",
    "                minus_plus[:, k] += self.epsilon\n",
    "\n",
    "                minus_minus[:, j] -= self.epsilon\n",
    "                minus_minus[:, k] -= self.epsilon\n",
    "\n",
    "                forward_forward = self.evaluate(plus_plus, index)\n",
    "                forward_backward = self.evaluate(plus_minus, index)\n",
    "                backward_forward = self.evaluate(minus_plus, index)\n",
    "                backward_backward = self.evaluate(minus_minus,index)\n",
    "                hessians[:, :, j, k] = (forward_forward - forward_backward - backward_forward + backward_backward) / (4 * self.epsilon **2)\n",
    "        return hessians.flatten(1,3)\n",
    "    \n",
    "    def loss_func(self, outputs, targets):\n",
    "        losses = []\n",
    "        outputs = outputs.permute(2,0,1)\n",
    "        targets = targets.permute(2,0,1)\n",
    "        for output, target in zip(outputs, targets):\n",
    "            loss = torch.mean(((target - output) ** 2), dim=1)\n",
    "            losses.append(loss)\n",
    "        total_losses = torch.mean(torch.stack(losses), dim=0)\n",
    "        #l2_reg = sum(p.pow(2.0).sum() for p in self.parameters())\n",
    "        #l1_reg = sum(p.abs().sum() for p in self.parameters())\n",
    "        #total_losses += 0.01 * l2_reg + 0.01 * l1_reg\n",
    "        return total_losses\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        target = inputs.squeeze(dim=2)\n",
    "        outs = torch.swapaxes(inputs, 1, 2).to(self.device)\n",
    "        outs = self.hidden_x1(outs)\n",
    "        xfc = torch.reshape(outs, (-1, 256))\n",
    "        xfc = self.hidden_xfc(xfc)\n",
    "\n",
    "        outs = torch.reshape(outs, (-1, 2, 128))\n",
    "        outs = self.hidden_x2(outs)\n",
    "        cnn_flat = self.flatten_layer(outs)\n",
    "        encoded = torch.cat((cnn_flat, xfc), 1)\n",
    "        embedding = self.hidden_embedding(encoded)\n",
    "\n",
    "        start_index = 0\n",
    "        losses = []\n",
    "        outputs = []\n",
    "        preds = []\n",
    "        pred_params = []\n",
    "        hessians =[]\n",
    "\n",
    "        print(self.num_params)\n",
    "        print(self.functions)\n",
    "        for f in range(len(self.functions)):\n",
    "            params = embedding[:, start_index:start_index+self.num_params[f]]\n",
    "            pred_params.append(params)\n",
    "            print(f\"params: {params.shape}\")\n",
    "            y_vals = self.evaluate(params, f).to(self.device)\n",
    "            d_vals = self.derivative(params, f).to(self.device)\n",
    "            #h_vals = self.hessian(params, f).to(self.device)\n",
    "            #hessians.append(h_vals)\n",
    "            #d_vals = F.pad(d_vals, (0,h_vals.shape[1]-d_vals.shape[1]))\n",
    "            #y_vals = F.pad(y_vals, (0,h_vals.shape[1]-y_vals.shape[1]))\n",
    "            d_vals = F.pad(d_vals, (0,2500-d_vals.shape[1]))\n",
    "            y_vals = F.pad(y_vals, (0,2500-y_vals.shape[1]))\n",
    "            #y_vals = F.pad(y_vals, (0,d_vals.shape[1]-y_vals.shape[1]))\n",
    "            # output = torch.stack([h_vals,d_vals,y_vals], dim=2).to(self.device)\n",
    "            output = torch.stack([d_vals,y_vals], dim=2).to(self.device)\n",
    "            outputs.append(output)\n",
    "            preds.append(y_vals)\n",
    "            loss = self.loss_func(output, target)\n",
    "            losses.append(loss)\n",
    "            start_index += self.num_params[f]  \n",
    "        print(pred_params[0].shape)\n",
    "        stacked_losses = torch.stack(losses).to(self.device)\n",
    "        stacked_preds = torch.stack(preds).to(self.device)\n",
    "        best_loss, best_indexes = torch.min(stacked_losses, dim=0)\n",
    "        best_out = stacked_preds[best_indexes, -1]\n",
    "        best_func = [self.functions[idx] for idx in best_indexes]\n",
    "        best_params = [pred_params[idx] for idx in best_indexes]\n",
    "        \n",
    "        return hessians, best_out, best_loss, best_func, best_params, stacked_preds, stacked_losses, pred_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loss_func(model, output, target):\n",
    "    target_max = torch.max(target, dim=-1, keepdim=True)[0]\n",
    "    target_min = torch.min(target, dim=-1, keepdim=True)[0]\n",
    "    target_range = torch.clamp(target_max - target_min, min=1e-6).squeeze(-1)\n",
    "    \n",
    "    mse_loss = torch.mean((output - target) ** 2, dim=-1)\n",
    "    normalized_loss = mse_loss / target_range\n",
    "    \n",
    "    #l2_reg = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "    #l1_reg = sum(p.abs().sum() for p in model.parameters())    \n",
    "    #total_loss = torch.mean(normalized_loss) + 0.01 * l2_reg + 0.01 * l1_reg\n",
    "    return torch.mean(normalized_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multi_Func_Channels(functions=functions, num_params=num_params, x_data=x_values, input_channels=2, device=device).to(device)\n",
    "\n",
    "dataloader = DataLoader(full_data, batch_size=1000, shuffle=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "# loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "k*x**3\n",
      "tensor([[-0.2316, -0.1946],\n",
      "        [ 0.0028, -0.1167],\n",
      "        [-0.2256, -0.1954],\n",
      "        ...,\n",
      "        [-0.2257, -0.1948],\n",
      "        [-0.2251, -0.1946],\n",
      "        [-0.2091, -0.1915]], device='cuda:4', grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "g*p*x\n",
      "tensor([[-0.1345, -0.0060,  0.0170],\n",
      "        [-0.0775,  0.0783,  0.2502],\n",
      "        [-0.1315, -0.0063,  0.0102],\n",
      "        ...,\n",
      "        [-0.1345, -0.0059,  0.0177],\n",
      "        [-0.1348, -0.0082,  0.0172],\n",
      "        [-0.1345, -0.0060,  0.0172]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "A*s*x**4\n",
      "tensor([[ -0.3545,   1.5061,   0.0212],\n",
      "        [ -0.5144,   1.5461,  -0.1906],\n",
      "        [  5.1920, -10.7726,   1.5855],\n",
      "        ...,\n",
      "        [ -0.5081,   1.5270,  -0.2037],\n",
      "        [ -0.5155,   1.5488,  -0.1910],\n",
      "        [  0.3911,  -1.0716,   1.0814]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "g*p*x\n",
      "tensor([[-0.0574,  0.3714,  0.1054],\n",
      "        [-0.0560,  0.3661,  0.1025],\n",
      "        [-2.0229, -4.5512, -4.3897],\n",
      "        ...,\n",
      "        [-0.0560,  0.3662,  0.1024],\n",
      "        [-0.0580,  0.3655,  0.1019],\n",
      "        [-0.0537,  0.3798,  0.1151]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "g*p*x\n",
      "tensor([[-0.8256, -2.4807, -1.0793],\n",
      "        [ 0.1494,  0.4393,  0.0952],\n",
      "        [ 0.1495,  0.4394,  0.0953],\n",
      "        ...,\n",
      "        [-0.3895, -1.4780, -0.5025],\n",
      "        [ 0.1464,  0.4361,  0.0913],\n",
      "        [ 0.1525,  0.4403,  0.0920]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "a*x**2/2\n",
      "tensor([[0.6993, 0.1326],\n",
      "        [0.7022, 0.1304],\n",
      "        [0.6692, 0.1501],\n",
      "        ...,\n",
      "        [0.6648, 0.1465],\n",
      "        [0.7115, 0.1232],\n",
      "        [0.7020, 0.1303]], device='cuda:4', grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "a*x**2/2\n",
      "tensor([[0.6417, 0.0722],\n",
      "        [0.6671, 0.0688],\n",
      "        [0.6387, 0.0370],\n",
      "        ...,\n",
      "        [0.6435, 0.0697],\n",
      "        [0.6414, 0.0737],\n",
      "        [0.6419, 0.0721]], device='cuda:4', grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "(a*x**2 + b*x)/(c*x**2 + d*x + e)\n",
      "tensor([[ 0.5066,  0.1350, -2.1192, -2.6179, -4.7561, -0.0799],\n",
      "        [ 0.5066,  0.1349, -2.1191, -2.6179, -4.7560, -0.0799],\n",
      "        [ 0.5054,  0.1328, -2.1176, -2.6148, -4.7476, -0.0765],\n",
      "        ...,\n",
      "        [ 0.4816,  0.1190, -2.0705, -2.5691, -4.6638, -0.0613],\n",
      "        [ 0.5055,  0.1336, -2.1176, -2.6168, -4.7519, -0.0787],\n",
      "        [ 0.4672,  0.1163, -2.0475, -2.5370, -4.6135, -0.0539]],\n",
      "       device='cuda:4', grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "(a*x**2 + b*x)/(c*x**2 + d*x + e)\n",
      "tensor([[ 0.7901,  0.0653, -2.9576, -3.6493, -6.2983, -0.1615],\n",
      "        [ 0.7687,  0.0475, -2.9154, -3.6181, -6.2262, -0.1487],\n",
      "        [ 0.7898,  0.0642, -2.9572, -3.6489, -6.2959, -0.1604],\n",
      "        ...,\n",
      "        [ 0.6457,  0.5913, -2.9219, -3.0020, -6.1269, -0.5790],\n",
      "        [ 0.7795,  0.0600, -2.9371, -3.6326, -6.2675, -0.1588],\n",
      "        [ 0.3615,  1.1462, -2.5930, -1.7659, -4.8582, -0.7656]],\n",
      "       device='cuda:4', grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "(a*x**2 + b*x)/(c*x**2 + d*x + e)\n",
      "tensor([[ 1.0069, -0.3587, -3.3872, -4.0924, -6.8953, -0.1695],\n",
      "        [ 0.9964, -0.3618, -3.3609, -4.0798, -6.8608, -0.1609],\n",
      "        [ 1.0358, -0.3205, -3.4866, -4.1030, -7.0203, -0.2245],\n",
      "        ...,\n",
      "        [ 0.9899, -0.3580, -3.3461, -4.0699, -6.8508, -0.1611],\n",
      "        [ 1.0057, -0.3597, -3.3857, -4.0908, -6.8911, -0.1679],\n",
      "        [ 1.0097, -0.3595, -3.3950, -4.0962, -6.9028, -0.1707]],\n",
      "       device='cuda:4', grad_fn=<SliceBackward0>)\n",
      "epoch : 0/50, loss = 0.14783081\n",
      "--- 9.555293321609497 seconds ---\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "(a*x**2 + b*x)/(c*x**2 + d*x + e)\n",
      "tensor([[ 0.8337, -0.6701, -3.6126, -4.2600, -6.9840, -0.1311],\n",
      "        [ 0.8325, -0.6697, -3.6096, -4.2576, -6.9804, -0.1302],\n",
      "        [ 0.8286, -0.6681, -3.5902, -4.2523, -6.9635, -0.1250],\n",
      "        ...,\n",
      "        [ 0.8334, -0.6698, -3.6122, -4.2592, -6.9839, -0.1311],\n",
      "        [ 0.8345, -0.6694, -3.6139, -4.2610, -6.9874, -0.1324],\n",
      "        [ 0.7900,  0.0209, -5.2549, -2.9998, -6.2261, -0.5857]],\n",
      "       device='cuda:4', grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "A*s*x**4\n",
      "tensor([[ 2.5653,  1.0209, -0.6559],\n",
      "        [ 2.5633,  1.3809, -0.5047],\n",
      "        [ 2.5616,  1.3788, -0.5038],\n",
      "        ...,\n",
      "        [ 2.5721,  1.3546, -0.5160],\n",
      "        [ 2.5563,  1.3872, -0.5002],\n",
      "        [ 2.5608,  1.3770, -0.5038]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "a*x**3/(b + c*x + d*x**2)\n",
      "tensor([[ 0.3015,  4.7426, -0.4184, -0.0530, -0.5578],\n",
      "        [-0.0209,  7.3287, -2.0747,  0.0246, -0.2618],\n",
      "        [ 0.3025,  4.7338, -0.4127, -0.0516, -0.5584],\n",
      "        ...,\n",
      "        [ 0.3006,  4.7404, -0.4216, -0.0546, -0.5559],\n",
      "        [ 0.2957,  4.7734, -0.4475, -0.0668, -0.5487],\n",
      "        [ 0.2957,  4.7784, -0.4499, -0.0674, -0.5495]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 6])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 5])\n",
      "params: torch.Size([1000, 3])\n",
      "params: torch.Size([1000, 2])\n",
      "torch.Size([1000, 4])\n",
      "a*x**2 + b*x + c\n",
      "tensor([[-5.8566, -1.4333,  0.8632,  1.0061],\n",
      "        [-4.2879, -0.5438,  2.3989,  0.2095],\n",
      "        [-4.3195, -0.5523,  2.3829,  0.2167],\n",
      "        ...,\n",
      "        [-4.2491, -0.5328,  2.4079,  0.2048],\n",
      "        [-5.4914, -1.2758,  1.1525,  0.8981],\n",
      "        [-4.2774, -0.5413,  2.4021,  0.2086]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([4, 2, 2, 4, 3, 6, 2, 5, 3, 2], device='cuda:4')\n",
      "[a*x**2 + b*x + c, k*x, a*x**2/2, G*m1*m2/x**2, g*p*x, (a*x**2 + b*x)/(c*x**2 + d*x + e), k*x**3, a*x**3/(b + c*x + d*x**2), A*s*x**4, t/x]\n",
      "params: torch.Size([1000, 4])\n",
      "params: torch.Size([1000, 2])\n",
      "params: torch.Size([1000, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m hessians, best_out, best_loss, best_func, best_params, stacked_preds, stacked_losses, pred_params \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m training_loss_func(model, best_out, batch[:, :, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m#loss_func(best_out, batch[:, :, 0])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#print(hessians[0])\u001b[39;00m\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FeynmanEquations/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[49], line 179\u001b[0m, in \u001b[0;36mMulti_Func_Channels.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m y_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(params, f)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 179\u001b[0m d_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mderivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m#h_vals = self.hessian(params, f).to(self.device)\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m#hessians.append(h_vals)\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#d_vals = F.pad(d_vals, (0,h_vals.shape[1]-d_vals.shape[1]))\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#y_vals = F.pad(y_vals, (0,h_vals.shape[1]-y_vals.shape[1]))\u001b[39;00m\n\u001b[1;32m    184\u001b[0m d_vals \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(d_vals, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2500\u001b[39m\u001b[38;5;241m-\u001b[39md_vals\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[49], line 93\u001b[0m, in \u001b[0;36mMulti_Func_Channels.derivative\u001b[0;34m(self, params, index)\u001b[0m\n\u001b[1;32m     91\u001b[0m     minus[:, p] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon\n\u001b[1;32m     92\u001b[0m     backward_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(minus, index)\n\u001b[0;32m---> 93\u001b[0m     derivatives[:, :, p] \u001b[38;5;241m=\u001b[39m (forward_values \u001b[38;5;241m-\u001b[39m backward_values) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m derivatives\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    total_num = 1\n",
    "    model.train()\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        batch = batch.requires_grad_(True).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hessians, best_out, best_loss, best_func, best_params, stacked_preds, stacked_losses, pred_params = model(batch[:, :, 0:2])\n",
    "        loss = training_loss_func(model, best_out, batch[:, :, 0]) #loss_func(best_out, batch[:, :, 0])\n",
    "        #print(hessians[0])\n",
    "        print(best_func[0])\n",
    "        print(best_params[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * best_out.shape[0]\n",
    "        total_num += best_out.shape[0]\n",
    "    scheduler.step()\n",
    "    train_loss /= total_num\n",
    "    print(f\"epoch : {epoch}/{epochs}, loss = {train_loss:.8f}\")\n",
    "    print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi_Func_Channels(\n",
      "  (hidden_x1): Sequential(\n",
      "    (0): Conv1d(3, 8, kernel_size=(7,), stride=(1,))\n",
      "    (1): SELU()\n",
      "    (2): Conv1d(8, 6, kernel_size=(7,), stride=(1,))\n",
      "    (3): SELU()\n",
      "    (4): Conv1d(6, 4, kernel_size=(5,), stride=(1,))\n",
      "    (5): SELU()\n",
      "    (6): AdaptiveAvgPool1d(output_size=64)\n",
      "  )\n",
      "  (hidden_xfc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (1): SELU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): SELU()\n",
      "    (4): Linear(in_features=32, out_features=20, bias=True)\n",
      "    (5): SELU()\n",
      "  )\n",
      "  (hidden_x2): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv1d(2, 4, kernel_size=(5,), stride=(1,))\n",
      "    (2): SELU()\n",
      "    (3): Conv1d(4, 4, kernel_size=(5,), stride=(1,))\n",
      "    (4): SELU()\n",
      "    (5): Conv1d(4, 4, kernel_size=(5,), stride=(1,))\n",
      "    (6): SELU()\n",
      "    (7): Conv1d(4, 4, kernel_size=(5,), stride=(1,))\n",
      "    (8): SELU()\n",
      "    (9): Conv1d(4, 4, kernel_size=(5,), stride=(1,))\n",
      "    (10): SELU()\n",
      "    (11): Conv1d(4, 4, kernel_size=(5,), stride=(1,))\n",
      "    (12): SELU()\n",
      "    (13): Conv1d(4, 4, kernel_size=(5,), stride=(1,))\n",
      "    (14): SELU()\n",
      "    (15): AdaptiveAvgPool1d(output_size=16)\n",
      "    (16): Conv1d(4, 2, kernel_size=(3,), stride=(1,))\n",
      "    (17): SELU()\n",
      "    (18): AdaptiveAvgPool1d(output_size=8)\n",
      "    (19): Conv1d(2, 2, kernel_size=(3,), stride=(1,))\n",
      "    (20): SELU()\n",
      "    (21): AdaptiveAvgPool1d(output_size=4)\n",
      "  )\n",
      "  (flatten_layer): Flatten(start_dim=1, end_dim=-1)\n",
      "  (hidden_embedding): Sequential(\n",
      "    (0): Linear(in_features=28, out_features=128, bias=True)\n",
      "    (1): SELU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): SELU()\n",
      "    (4): Linear(in_features=64, out_features=33, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2201610/2087370462.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  other_model = torch.load('model.pth')\n"
     ]
    }
   ],
   "source": [
    "other_model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_func: [a*x**3/(b + c*x + d*x**2)]\n",
      "best_loss: tensor([0.0004], device='cuda:4', grad_fn=<MinBackward0>)\n",
      "best_params: [tensor([[-0.0295, -9.2733,  0.1081, -7.9500, -0.7225]], device='cuda:4',\n",
      "       grad_fn=<SliceBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbc84d455d0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "ran = np.random.randint(5000, full_data.shape[0])\n",
    "h, best_out, best_loss, best_func, best_params, stacked_preds, stacked_losses, pred_params = model(full_data[ran, :, 0:2].unsqueeze(0))\n",
    "print(f\"best_func: {best_func}\")\n",
    "print(f\"best_loss: {best_loss}\")\n",
    "print(f\"best_params: {best_params}\")\n",
    "plt.plot(x_values.detach().cpu().numpy(), y_values[ran].detach().cpu().numpy(), label='True')\n",
    "plt.plot(x_values.detach().cpu().numpy(), best_out.squeeze(0)[0:100].detach().cpu().numpy(), label='Predicted')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
