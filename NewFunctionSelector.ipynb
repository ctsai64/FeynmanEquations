{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1555889/135975362.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load('hold_data.pth')\n"
     ]
    }
   ],
   "source": [
    "loaded_data = torch.load('hold_data.pth')\n",
    "\n",
    "x_values = loaded_data['x_values']\n",
    "y_values = loaded_data['y_values']\n",
    "derivatives = loaded_data['derivatives']\n",
    "hessians = loaded_data['hessians']\n",
    "params = loaded_data['param_values']\n",
    "formulas = loaded_data['formulas']\n",
    "symbols = loaded_data['symbols']\n",
    "num_params = loaded_data['num_params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Func_Channels(nn.Module):\n",
    "    def __init__(self, functions, num_params, x_data, input_channels, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.formulas = functions\n",
    "        self.x_data = x_data\n",
    "        self.input_channels = input_channels\n",
    "        self.num_params = num_params\n",
    "        self.max_params = max(num_params)\n",
    "        self.symbols = symbols\n",
    "        self.params = sum(self.num_params)\n",
    "        self.epsilon = 1e-4\n",
    "\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.input_channels, out_channels=8, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(64)\n",
    "        )\n",
    "\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(32, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(16),\n",
    "            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(8),\n",
    "            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AdaptiveAvgPool1d(4),\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(28, 128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, self.params),\n",
    "        )\n",
    "\n",
    "    def evaluate(self, params, index):\n",
    "        symbols = self.symbols[index]\n",
    "        formula = self.formulas[index]\n",
    "        x = self.x_data\n",
    "        var_values = {symbols[j]: params[:, j] for j in range(len(symbols)-1)}\n",
    "        eval_func = sp.lambdify(symbols, formula, modules=\"numpy\")\n",
    "        results = []\n",
    "        for xi in x:\n",
    "            var_values[symbols[-1]] = xi\n",
    "            np_values = {str(sym): var_values[sym].detach().cpu().numpy() for sym in symbols}\n",
    "            results.append(eval_func(**np_values))\n",
    "        tensor_results = [torch.tensor(r, device=device) for r in results]\n",
    "        return torch.stack(tensor_results, dim=1)\n",
    "    \n",
    "    def derivative(self, params, index):\n",
    "        derivatives = torch.zeros(params[0], params[1], self.max_params)\n",
    "        params_n = params.clone().detach().requires_grad_(True)\n",
    "        for p in range(len(symbols[index])):\n",
    "            plus = params_n.clone()\n",
    "            minus = params_n.clone()\n",
    "            plus[:,p] += self.epsilon\n",
    "            forward_values = self.evaluate_function(plus, index)\n",
    "            minus[:, p] -= self.epsilon\n",
    "            backward_values = self.evaluate_function(minus, index)\n",
    "            derivatives[:, :, p] = (forward_values - backward_values) / (2 * self.epsilon)\n",
    "\n",
    "    def hessian(self, params, index):\n",
    "        hessians = torch.zeros(params[0], params[1], self.max_params, self.max_params)\n",
    "        params_f = params.clone().detach().requires_grad_(True)\n",
    "        for j in range(len(symbols[f])):\n",
    "            for k in range(len(symbols[f])):\n",
    "                plus_plus = params_f.clone()\n",
    "                plus_minus = params_f.clone()\n",
    "                minus_plus = params_f.clone()\n",
    "                minus_minus = params_f.clone()\n",
    "\n",
    "                plus_plus[:, j] += self.epsilon\n",
    "                plus_plus[:, k] += self.epsilon\n",
    "\n",
    "                plus_minus[:, j] += self.epsilon\n",
    "                plus_minus[:, k] -= self.epsilon\n",
    "\n",
    "                minus_plus[:, j] -= self.epsilon\n",
    "                minus_plus[:, k] += self.epsilon\n",
    "\n",
    "                minus_minus[:, j] -= self.epsilon\n",
    "                minus_minus[:, k] -= self.epsilon\n",
    "\n",
    "                forward_forward = self.evaluate_function(plus_plus, index)\n",
    "                forward_backward = self.evaluate_function(plus_minus, index)\n",
    "                backward_forward = self.evaluate_function(minus_plus, index)\n",
    "                backward_backward = self.evaluate_function(minus_minus,index)\n",
    "                hessians[:, :, j, k] = (forward_forward - forward_backward - backward_forward + backward_backward) / (4 * epsilon **2)\n",
    "\n",
    "\n",
    "    def forward(self, x, n=-1):\n",
    "        target = x.squeeze(dim=2)\n",
    "        x = torch.swapaxes(x, 1, 2).to(self.device)\n",
    "        x = self.hidden_x1(x)\n",
    "        xfc = torch.reshape(x, (n, 256))\n",
    "        xfc = self.hidden_xfc(xfc)\n",
    "\n",
    "        x = torch.reshape(x, (n, 2, 128))\n",
    "        x = self.hidden_x2(x)\n",
    "        cnn_flat = self.flatten_layer(x)\n",
    "        encoded = torch.cat((cnn_flat, xfc), 1)\n",
    "        embedding = self.hidden_embedding(encoded)\n",
    "\n",
    "        loss_func = nn.MSELoss()\n",
    "        start_index = 0\n",
    "        losses = []\n",
    "        outputs = []\n",
    "        \n",
    "        for f in range(len(self.functions[0])):\n",
    "            output = self.functions[0][f](\n",
    "                embedding[:, start_index:start_index+self.functions[1][f]], \n",
    "                self.x_data, \n",
    "                device=self.device\n",
    "            ).to(device)\n",
    "            outputs.append(output)\n",
    "            loss = loss_func(output, target)\n",
    "            losses.append(loss)\n",
    "            start_index += self.functions[1][f]        \n",
    "        best_index = torch.argmin(torch.tensor(losses))\n",
    "        best_func = self.functions[0][best_index]\n",
    "        best_loss, best_out = losses[best_index], outputs[best_index]\n",
    "\n",
    "        return best_out, best_loss, best_func, outputs, losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
